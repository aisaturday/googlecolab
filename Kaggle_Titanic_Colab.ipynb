{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle-Titanic-Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Nl923j6ixZbw",
        "HPhXEYHFLxPJ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/todun/googlecolab/blob/master/Kaggle_Titanic_Colab.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "BV_plosvUgae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# About "
      ]
    },
    {
      "metadata": {
        "id": "EzU6WPam3uQH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Kaggle Competition | Titanic Machine Learning from Disaster\n",
        "\n",
        ">The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.  This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
        "\n",
        ">One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew.  Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
        "\n",
        ">In this contest, we ask you to complete the analysis of what sorts of people were likely to survive.  In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
        "\n",
        ">This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n",
        "\n",
        "From the competition [homepage](http://www.kaggle.com/c/titanic-gettingStarted)."
      ]
    },
    {
      "metadata": {
        "id": "cBxpcysu3yrG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Goal for this Notebook:\n",
        "End to end example of predicting survival of Titanic passengers with Goggle Colaboratory PaaS using:\n",
        "\n",
        "* Kaggle API\n",
        "* Python 3\n",
        "* Github\n",
        "* Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "s8jkgHSW3ypP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### This Notebook will show basic examples of: \n"
      ]
    },
    {
      "metadata": {
        "id": "MEbnxe8J3-m4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Data Handling\n",
        "* Getting dataset with Kaggle CLI\n",
        "* Importing Data with Pandas\n",
        "* Cleaning Data\n",
        "* Submitting predictions with Kaggle CLI\n",
        "* Mounting Google Drive as a partition in Google Colab\n",
        "* Using github for file transfer\n"
      ]
    },
    {
      "metadata": {
        "id": "JRd0bChz4BMp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Data Analysis\n",
        "Various libraries"
      ]
    },
    {
      "metadata": {
        "id": "cBYwR7e-4DPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Valuation of the Analysis\n",
        "* Output the results from the IPython Notebook to Kaggle"
      ]
    },
    {
      "metadata": {
        "id": "e_0l3fxW4GbV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Required Libraries:\n",
        "* [NumPy](http://www.numpy.org/)\n",
        "* [IPython](http://ipython.org/)\n",
        "* [Pandas](http://pandas.pydata.org/)\n",
        "* [SciKit-Learn](http://scikit-learn.org/stable/)\n",
        "* [SciPy](http://www.scipy.org/)\n",
        "* [StatsModels](http://statsmodels.sourceforge.net/)\n",
        "* [Patsy](http://patsy.readthedocs.org/en/latest/)\n",
        "* [Matplotlib](http://matplotlib.org/)"
      ]
    },
    {
      "metadata": {
        "id": "8tYP1OjV4J-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### References\n",
        "* [Official Kaggle CLI API](https://github.com/kaggle/kaggle-api)\n",
        "* [Collection of google colaboratory notebooks](https://github.com/todun/googlecolab)\n",
        "* [Kaggle](https://www.kaggle.com/)\n",
        "* [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
        "* [Tutorial on Using Google Colab for Kaggle Competition](https://medium.com/@burakteke/tutorial-on-using-google-colab-for-kaggle-competition-620393c22821)\n",
        "* [Make your Kaggle Submissions with Kaggle Official API!](https://medium.com/@nokkk/make-your-kaggle-submissions-with-kaggle-official-api-f49093c04f8a)\n",
        "* [Google Colaboratory Cheat Sheet](https://medium.com/@rahul.metangale/google-colaboratory-cheat-sheet-24b99813b0f0)\n",
        "* [How to Upload large files to Google Colab and remote Jupyter notebooks](https://medium.freecodecamp.org/how-to-transfer-large-files-to-google-colab-and-remote-jupyter-notebooks-26ca252892fa)\n",
        "* [INTRODUCTION TO CONVOLUTIONAL NEURAL NETWORKS](https://medium.com/@johnolafenwa/introduction-to-convolutional-neural-networks-60e113744c4)\n",
        "* [COMPONENTS OF NEURAL NETWORKS](https://medium.com/@johnolafenwa/components-of-neural-networks-2787589f464c)\n",
        "* [INTRODUCTION TO NEURAL NETWORKS](https://medium.com/@johnolafenwa/introduction-to-neural-networks-ca7eab1d27d7)\n",
        "* [Running Jupyter Notebook on Colab](https://medium.com/@margaretmz/running-jupyter-notebook-with-colab-f4a29a9c7156)"
      ]
    },
    {
      "metadata": {
        "id": "T8F9DTV6OzMZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 0. Define global variables\n",
        "\n",
        "These are *NOT HYPER PARAMETERS* and primarily for code maintenance"
      ]
    },
    {
      "metadata": {
        "id": "U8WhXTpuO2mz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "KAGGLE_COMPETITION_NAME='titanic'\n",
        "GDRIVE_ROOT='/content/my_google_drive'\n",
        "GDRIVE_KAGGLE_TITANIC='/content/my_google_drive/kaggle-titanic'\n",
        "GDRIVE_KAGGLE_TITANIC_AI_CODE='/content/my_google_drive/kaggle-titanic/kt-ai-code'\n",
        "RESULTS='/content/my_google_drive/kaggle-titanic/results'\n",
        "RESULT_CSV='/content/my_google_drive/kaggle-titanic/results/submission.csv'\n",
        "\n",
        "KAGGLE_CLI_COLAB_DATA='/content/.kaggle/competitions'\n",
        "KAGGLE_CLI_COLAB_ROOT='/content/.kaggle'\n",
        "\n",
        "IS_MAX_SCORE_SUBMISSION = True # create submission.csv of maximum result\n",
        "FINAL = False # indicate the predication using trained models is saved to CSV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7DaIn0IPqj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. link google drive to google colaboratory file system\n",
        "\n",
        "This mounts the google drive as a file system in the google colaboratory Virtual Machine(VM)"
      ]
    },
    {
      "metadata": {
        "id": "tqp4HOv8Pt7U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcR0nPLGPw3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### mount my google drive"
      ]
    },
    {
      "metadata": {
        "id": "e7BiUpl-PzJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p my_google_drive\n",
        "!google-drive-ocamlfuse my_google_drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EZ6lbN86d9v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### put titanic dataset into google drive"
      ]
    },
    {
      "metadata": {
        "id": "JFIc_IT28yPv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Create folder for competition data & AI"
      ]
    },
    {
      "metadata": {
        "id": "G8gBcj5WPH3g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $GDRIVE_ROOT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G0xZ14Yp6kZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir $GDRIVE_ROOT/kaggle-titanic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2g7U7fj6wwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### check your related drive folder exist or not."
      ]
    },
    {
      "metadata": {
        "id": "TTSuI-ri8_HC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $GDRIVE_KAGGLE_TITANIC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bD_S7HEb9Dg0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Link to kaggle\n",
        "\n",
        "Use the Kaggle CLI to get the competition dataset"
      ]
    },
    {
      "metadata": {
        "id": "dFDtHO4O9IFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### install kaggle"
      ]
    },
    {
      "metadata": {
        "id": "AbU95PO39L_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nl923j6ixZbw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### kaggle API Credentials\n",
        "\n",
        "To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com. Then go to the 'Account' tab of your user profile (https://www.kaggle.com//account) and select 'Create API Token'. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "\n",
        "Place this file on your Google Drive anywhere.\n",
        "\n",
        "With the next snippet you download your credentials to Colab and you can start using Kaggle API"
      ]
    },
    {
      "metadata": {
        "id": "Zp7hFxRMxrCh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### manually upload kaggle.json to (anywhere ) on google drive"
      ]
    },
    {
      "metadata": {
        "id": "ZQSYYxDMyC1N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### transfer kaggle api keys from google drive to colab file system"
      ]
    },
    {
      "metadata": {
        "id": "acQW93ajxYMC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1YUimI2yVco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### confirm transfer of kaggle api keys to google colab"
      ]
    },
    {
      "metadata": {
        "id": "iWOFLY-Cyawg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $KAGGLE_CLI_COLAB_ROOT/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63SFUzDt2py5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### manually delete kaggle.json from google drive"
      ]
    },
    {
      "metadata": {
        "id": "fBuOkIYo2Rhk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### confirm manual delete of kaggle.json from google drive\n",
        "Should get an error like\n",
        "\n",
        "    ls: cannot access '/content/my_google_drive/kaggle.json': No such file or directory"
      ]
    },
    {
      "metadata": {
        "id": "CBTZo1tD2VPD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $GDRIVE_ROOT/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZX87zbH_ySi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### download dataset from kaggle\n",
        "using the official kaggle cli "
      ]
    },
    {
      "metadata": {
        "id": "IFGPB5yl_0yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c $KAGGLE_COMPETITION_NAME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70SRCU_t2G9R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### confirm data download"
      ]
    },
    {
      "metadata": {
        "id": "UWTmA0GQ2JY5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $KAGGLE_CLI_COLAB_DATA/$KAGGLE_COMPETITION_NAME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LKzWBJzPA0Lw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### move kaggle data into gdrive data folder\n",
        "\n",
        "uploaded all of the competiton data from kaggle to mounted g-drive folder “kaggle-titanic”"
      ]
    },
    {
      "metadata": {
        "id": "3lgLXmLrBPH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp $KAGGLE_CLI_COLAB_DATA/$KAGGLE_COMPETITION_NAME/* $GDRIVE_KAGGLE_TITANIC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8K0IKA7pB31b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### verify data folder contents"
      ]
    },
    {
      "metadata": {
        "id": "xfuMzFMKB50Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $GDRIVE_KAGGLE_TITANIC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fn7Nzh7NCC0m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### put AI code into mounted google drive"
      ]
    },
    {
      "metadata": {
        "id": "3bZT58sbCO1b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### [Download and move classifier folder/files into created GDrive folder](https://medium.freecodecamp.org/how-to-transfer-large-files-to-google-colab-and-remote-jupyter-notebooks-26ca252892fa)\n",
        "Use github for file transfer"
      ]
    },
    {
      "metadata": {
        "id": "8b5oCd50CIet",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf $GDRIVE_KAGGLE_TITANIC_AI_CODE\n",
        "!pip install -q xlrd\n",
        "!git clone https://github.com/aisaturday/kaggle-titanic-ai-code\n",
        "!mkdir $GDRIVE_KAGGLE_TITANIC/kt-ai-code  \n",
        "!mv ./kaggle-titanic-ai-code/*.py ./kaggle-titanic-ai-code/*.txt $GDRIVE_KAGGLE_TITANIC/kt-ai-code  \n",
        "!rm -rf ./kaggle-titanic-ai-code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8nrByZIGU9tC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### verify AI code"
      ]
    },
    {
      "metadata": {
        "id": "NwkfsC9NU_ij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $GDRIVE_KAGGLE_TITANIC_AI_CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dctuV4piHcDs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### [import a python file from google drive into google colab python environment](https://stackoverflow.com/a/20749411)\n"
      ]
    },
    {
      "metadata": {
        "id": "bsK2pSTmHcjF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys \n",
        "import os\n",
        "sys.path.append(os.path.abspath(\"/content/my_google_drive/kaggle-titanic/kt-ai-code\"))\n",
        "\n",
        "!pip install -r $GDRIVE_KAGGLE_TITANIC_AI_CODE/requirements.txt\n",
        "\n",
        "import titanic_predict as tp # see https://github.com/aisaturday/kaggle-titanic-ai-code for more details"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OeKhrbRkQAYA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### verify mount to my google drive"
      ]
    },
    {
      "metadata": {
        "id": "TIpGv51UP39b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $GDRIVE_KAGGLE_TITANIC_AI_CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RUTSgALQFju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. setup project"
      ]
    },
    {
      "metadata": {
        "id": "1Y7dNUmqQPdn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Handling\n",
        "#### Let's read our data in using pandas:"
      ]
    },
    {
      "metadata": {
        "id": "kRfl01gR3mf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "train_data = pd.read_csv('/content/my_google_drive/kaggle-titanic/train.csv')\n",
        "test_data = pd.read_csv('/content/my_google_drive/kaggle-titanic/test.csv')\n",
        "p_id = test_data['PassengerId']\n",
        "data = pd.concat([train_data, test_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N6z9QcEEQXXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's take a look:\n",
        "\n",
        "train.csv **data** has 891 observations, or passengers, to analyze here:\n",
        "    \n",
        "    Int64Index: 891 entries, 0 to 890\n",
        "\n",
        "Each column tells us something about each of our observations, like their `name`, `sex` or `age`. These colunms  are called a features of our dataset. You can think of the meaning of the words column and feature as interchangeable for this notebook. \n",
        "\n",
        "After each feature it lets us know how many values it contains. While most of our features have complete data on every observation, like the `survived` feature here: \n",
        "\n",
        "    survived    891  non-null values \n",
        "\n",
        "some are missing information, like the `age` feature: \n",
        "\n",
        "    age         714  non-null values \n",
        "\n",
        "These missing values are represented as `NaN`s.\n",
        "\n",
        "### Take care of missing values:\n",
        "The features `ticket` and `cabin` have many missing values and so can’t add much value to our analysis. To handle this we will drop them from the dataframe to preserve the integrity of our dataset.\n",
        "\n",
        "To do that we'll use this line of code to drop the features entirely:\n",
        "\n",
        "    df = df.drop(['ticket','cabin'], axis=1) \n",
        "\n",
        "\n",
        "While this line of code removes the `NaN` values from every remaining column / feature:\n",
        "   \n",
        "    df = df.dropna()\n",
        "     \n",
        "Now we have a clean and tidy dataset that is ready for analysis. Because `.dropna()` removes an observation from our data even if it only has 1 `NaN` in one of the features, it would have removed most of our dataset if we had not dropped the `ticket` and `cabin`  features first.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "waAUDM523mf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.drop('PassengerId', axis=1, inplace=True)\n",
        "survived = data['Survived'].dropna()\n",
        "data['Survived'].fillna(-1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q36AeuRc3mgF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "processed_data = tp.preprocess_data(data)\n",
        "\n",
        "training_data = processed_data[data['Survived'] != -1]\n",
        "testing_data = processed_data[data['Survived'] == -1]\n",
        "\n",
        "training_data.drop('Survived', axis=1, inplace=True)\n",
        "testing_data.drop('Survived', axis=1, inplace=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(training_data, survived, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UHh11FbYUpba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Training the models\n",
        "\n",
        "This is used to generate models that perform the predictions"
      ]
    },
    {
      "metadata": {
        "id": "F7-2B6vHbALH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### get pretrained models\n",
        "\n",
        "These are gotten via sklearn python library"
      ]
    },
    {
      "metadata": {
        "id": "28CyQZXsagL2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnEmRvBuaq6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### train using transfer learning\n",
        "Using pre-trained models, the training is done faster"
      ]
    },
    {
      "metadata": {
        "id": "GtKv0I5w3mgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    DecisionTreeClassifier(max_depth=10),\n",
        "    RandomForestClassifier(n_estimators=100),\n",
        "    MLPClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()\n",
        "]\n",
        "\n",
        "scores ={} # dictionary of model with associated accuracy score\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_test, y_test)\n",
        "    scores[model] = score\n",
        "    print(score)\n",
        "    \n",
        "model_with_max_score = max(scores, key=lambda k: scores[k])   \n",
        "print(f\"{model_with_max_score} has maximum score of {scores[model_with_max_score]}\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xoy8SWeWUs8Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Predicting with models\n",
        "\n",
        "To see how well (how minimized the training loss) training is done, predictions are done with unseen test dataset"
      ]
    },
    {
      "metadata": {
        "id": "HPhXEYHFLxPJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### create results directory\n",
        "used to store predictions made with the trained models\n"
      ]
    },
    {
      "metadata": {
        "id": "Y8o7u0D1L5ry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir $GDRIVE_KAGGLE_TITANIC/results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49DbuCA-oWtr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### verify results"
      ]
    },
    {
      "metadata": {
        "id": "QcubKhYjdgnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls $RESULTS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGJAt6CxMQzJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### TIPS\n"
      ]
    },
    {
      "metadata": {
        "id": "bubQ9aoeob9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "* [**numpy.savetxt** without hash mark at beginning of header line](https://stackoverflow.com/a/17361181)\n",
        "\n",
        "      If you want to get rid of it, pass comments='' as option to savetxt.\n",
        "\n",
        "* [Saving arrays as columns with np.savetxt](https://stackoverflow.com/a/15193026)\n",
        "\n",
        "      np.savetxt('myfile.txt', np.c_[x,y,z])\n",
        "      \n",
        "* [Writing CSV files with NumPy and pandas](https://www.packtpub.com/mapt/book/big_data_and_business_intelligence/9781783553358/5/ch05lvl1sec50/writing-csv-files-with-numpy-and-pandas)\n",
        "\n",
        "      The NumPy savetxt() function is the counterpart of the NumPy loadtxt() function and can save arrays in delimited file formats such as CSV. Save the array we created with the following function call:\n",
        "      \n",
        "      np.savetxt('np.csv', a, fmt='%.2f', delimiter=',', header=\" #1,  #2,  #3,  #4\")\n",
        "      \n",
        "* [**numpy.savetxt** *fmt* parameter ](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.savetxt.html)     \n",
        "\n",
        "      d or i : signed decimal integer\n",
        "\n",
        "      e or E : scientific notation with e or E.\n",
        "\n",
        "      f : decimal floating point\n",
        "\n",
        "      g,G : use the shorter of e,E or f\n",
        "\n",
        "      o : signed octal\n",
        "\n",
        "      s : string of characters\n",
        "\n",
        "      u : unsigned decimal integer\n",
        "     "
      ]
    },
    {
      "metadata": {
        "id": "UP84d_Rh3mgO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if IS_MAX_SCORE_SUBMISSION:\n",
        "    model.fit(training_data, survived)\n",
        "    prediction = model.predict(testing_data)\n",
        "    np.savetxt('/content/my_google_drive/kaggle-titanic/results/submission.csv', np.c_[p_id, prediction], fmt=['%g', '%g'], delimiter=\",\", header=\"PassengerId,Survived\", comments='')                \n",
        "    \n",
        "if FINAL:\n",
        "\n",
        "    models = [\n",
        "        KNeighborsClassifier(3),\n",
        "        SVC(kernel=\"linear\", C=0.025),\n",
        "        SVC(gamma=2, C=1),\n",
        "        DecisionTreeClassifier(max_depth=10),\n",
        "        RandomForestClassifier(n_estimators=100),\n",
        "        MLPClassifier(),\n",
        "        AdaBoostClassifier(),\n",
        "        GaussianNB(),\n",
        "        QuadraticDiscriminantAnalysis()\n",
        "    ]    \n",
        "    \n",
        "    for model in models:\n",
        "        model.fit(training_data, survived)\n",
        "        prediction = model.predict(testing_data)\n",
        "        np.savetxt('/content/my_google_drive/kaggle-titanic/results/submission-{}.csv'.format(model), np.c_[p_id, prediction], fmt=['%g', '%g'], delimiter=\",\", header=\"PassengerId,Survived\", comments='')                \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gp2OkdYXLFFl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5.  [Submit the Result wtih Kaggle CLI](https://www.kaggle.com/c/titanic/)\n",
        "\n",
        "Use the official Kaggle CLI to make submissions to titanic kaggle competion ***AFTER the COMPETITION RULES HAVE BEEN ACCEPTED*** or the kaggle submission would fail\n"
      ]
    },
    {
      "metadata": {
        "id": "vB2TzvblLf75",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### view previous submissions\n",
        "using the official kaggle cli "
      ]
    },
    {
      "metadata": {
        "id": "2PpOR-TrPhFT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submissions -c $KAGGLE_COMPETITION_NAME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJVSKX6RLjLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### make submission to kaggle\n",
        "using the official kaggle cli "
      ]
    },
    {
      "metadata": {
        "id": "oaT1oYESsGyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c $KAGGLE_COMPETITION_NAME -f $RESULT_CSV  -m 'test kaggle cli 3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lI2htBC9py17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### confirm kaggle submission"
      ]
    },
    {
      "metadata": {
        "id": "kQhGr5smp1NH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submissions -c $KAGGLE_COMPETITION_NAME"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}